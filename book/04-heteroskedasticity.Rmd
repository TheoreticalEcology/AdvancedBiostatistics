--- 
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    highlight: kate
documentclass: book
---


# Heteroskedasticity and Grouped Data (Random Effects) {#heteroskedasticity}

```{=html}
<!-- Put this here (right after the first markdown headline) and only here for each document! -->
<script src="./scripts/multipleChoice.js"></script>
```

In this chapter, we check lm() and change the functional for our variance terms to improve the model.


## Warm-up Exercise

The following data set contains information about life satisfaction in Germany, based on the socio-economic panel. 

```{r chunk_chapter4_chunk1, echo=TRUE, eval=FALSE}
satisf = read.csv(file = "https://www.dropbox.com/s/sggy9b9xb0rekkx/soep_satisfcation.csv?dl=1")
```

```{=html}
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
```

Perform an exploratory causal analysis of the data to find out what determines life satisfaction and if the effect of those factors has changed over time. 

```{=html}
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
```

```{r chunk_chapter4_task_0, message=FALSE, warning=FALSE}

```

```{=html}
    </p>
  </details>
  <br/><hr/>
```


## General Modelling Strategy for lm() + Correction of Residuals

With all the discussion about causality, model selection etc., we can re-visit the question of how to build an appropriate lm(). My basic modelling strategy for a causal lm() analysis is the following:

First, think about the problem and your question an decide on a base structure. Ideally, you do this by:

* Writing down your scientific questions (e.g. Ozone ~ Wind)
* Then add confounders if needed.
* Remember to make a difference between variables controlled for confounding, and other confounders (which are typically not controlled for confounding). We may have to use some model selection, but in fact with a good analysis plan this is rarely necessary for a causal analysis.

Then, we have to check if the model fits all right. Yesterday, we already discussed about residual checks and we discussed that the 4 standard residual plots check for 4 different problems:

* Residuals vs Fitted = Functional relationship.
* Normal Q-Q = Normality of residuals.
* Scale - Location = Variance homogeneity.
* Residuals vs Leverage = Should we worry about certain outliers?

```{r chunk_chapter4_chunk2, echo=TRUE, eval=TRUE}
fit = lm(Ozone ~ Temp , data = airquality)
par(mfrow = c(2, 2))
plot(fit)
```

It is usually recommended to solve the problems of the plots in that order, i.e.:

* First worry about the functional relationship.
* Then about the distribution, variance and outliers.

Today's topic will mostly be about plot 3, the variance modelling. Before we come to that, however, a few more hints about how to deal with plots 1 and 2 (see the following sections).


### Wrong Functional Form

What do we do if we have the wrong functional form in the Scale - Location plot? Here a few strategies that you might want to consider:

The easiest strategy is to add complexity to the polynomial, e.g. quadratic terms, interactions etc.

```{r chunk_chapter4_chunk3, echo=TRUE, eval=FALSE}
fit = lm(Ozone ~ Wind * Temp + I(Wind^2) + I(Temp^2), data = airquality)
```

and see if the residuals are getting better. To avoid doing this totally randomly, it may be useful to plot residuals against individual predictors by hand!

***GAMs***

Another options are GAMs = Generalized Additive Models. The idea is to fit a smooth function to data, to automatically find the "right" functional form. The smoothness of the function is automatically optimized.

```{r chunk_chapter4_chunk4, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(mgcv)

fit = gam(Ozone ~ s(Wind) + s(Temp) + s(Solar.R) , data = airquality)
summary(fit)

plot(fit, pages = 1, residuals = T)
AIC(fit)
```

Comparison to normal lm():

```{r chunk_chapter4_chunk5, echo=TRUE, eval=TRUE}
fit = lm(Ozone ~ Wind + Temp + Solar.R , data = airquality)
AIC(fit)
```

Spline interaction is called a **tensor spline**:

```{r chunk_chapter4_chunk6, echo=TRUE, eval=TRUE}
fit = gam(Ozone ~ te(Wind, Temp) + s(Solar.R) , data = airquality)
summary(fit)

plot(fit, pages = 1, residuals = T)
AIC(fit)
```

GAMs are particularly useful for confounders. If you have confounders, you usually don't care that the fitted relationship is a bit hard to interpret, you just want the confounder effect to be removed. So, if you want to fit the causal relationship between Ozone ~ Wind, account for the other variables, a good strategy might be:

```{r chunk_chapter4_chunk7, echo=TRUE, eval=TRUE}
fit = gam(Ozone ~ Wind + s(Temp) + s(Solar.R) , data = airquality)
summary(fit)
```

In this way, you still get a nicely interpretable linear effect for Wind, but you don't have to worry about the functional form of the other predictors.


### Modelling Variance Terms

After we have fixed the functional form, we want to look at the distribution of the residuals. We said yesterday that you can try to get them more normal by applying an appropriate transformation, e.g. the logarithm or square root. Without transformation, we often find that data shows heteroskedasticity, i.e. the residual variance changes with some predictor or the mean estimate (see also Scale - Location plot). Maybe your experimental data looks like this:

```{r chunk_chapter4_chunk8, echo=TRUE, eval=TRUE}
set.seed(125)

data = data.frame(treatment = factor(rep(c("A", "B", "C"), each = 15)))
data$observation = c(7, 2 ,4)[as.numeric(data$treatment)] +
  rnorm( length(data$treatment), sd = as.numeric(data$treatment)^2 )
boxplot(observation ~ treatment, data = data)
```

Especially p-values and confidence intervals of lm() and ANOVA can react quite strongly to such differences in residual variation. So, running a standard lm() / ANOVA on this data is not a good idea - in this case, we see that all regression effects are not significant, as is the ANOVA, suggesting that there is no difference between groups.

```{r chunk_chapter4_chunk9, echo=TRUE, eval=TRUE}
fit = lm(observation ~ treatment, data = data)
#summary(fit)
summary(aov(fit))
```

So, what can we do?

**Option 1**: Find a transformation of the response  - If heteroskedasticity correlates with the mean value, one can typically decrease it by some sqrt or log transformation, but often difficult, because this may also conflict with keeping the distribution normal.

**Option 2**: Model the variance - Modelling the variance to fit a model where the variance is not fixed. The basic option in R is `nlme::gls`{.R}. GLS = Generalized Least Squares. In this function, you can specify a dependency of the residual variance on a predictor or the response. See options via `?varFunc`{.R}. In our case, we will use the varIdent option, which allows to specify a different variance per treatment.

```{r chunk_chapter4_chunk10, echo=TRUE, eval=TRUE}
library(nlme)

fit = gls(observation ~ treatment, data = data, weights = varIdent(form = ~ 1 | treatment))
summary(fit)
```

If you check the ANOVA, also the ANOVA is significant!

```{r chunk_chapter4_chunk11, echo=TRUE, eval=TRUE}
anova(fit)
```

The second option for modeling variances is to use the glmmTMB package, which we will use quite frequently this week. Here, you can specify an extra regression formula for the dispersion (= residual variance). If we fit this:

```{r chunk_chapter4_chunk12, echo=TRUE, eval=TRUE}
library(glmmTMB)

fit = glmmTMB(observation ~ treatment, data = data, dispformula = ~ treatment)
```

We get 2 regression tables as outputs - one for the effects, and one for the dispersion (= residual variance). We see, as expected, that the dispersion is higher in groups B and C compared to A. An advantage over gls is that we get confidence intervals and p-values for these differences on top!

```{r chunk_chapter4_chunk13, echo=TRUE, eval=TRUE}
summary(fit)
```


### Exercise

Take this plot of Ozone ~ Solar.R using the airquality data. Clearly there is heteroskedasticity in the relationship:

```{r chunk_chapter4_chunk14, echo=TRUE, eval=TRUE}
plot(Ozone ~ Solar.R, data = airquality)
```

We can also see this when we fit the regression model:

```{r chunk_chapter4_chunk15, echo=TRUE, eval=FALSE}
m1 = lm(Ozone ~ Solar.R, data = airquality)
par(mfrow = c(2, 2))
plot(m1)
```

```{=html}
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
```

We could of course consider other predictors, but let's say we want to fit this model specifically

1. Try to get the variance stable with a transformation.
2. Use the gls function with the untransformed response to make the variance dependent on Solar.R. Hint: Read in corClasses and decide how to model this.
3. Use glmmTMB to model heteroskedasticity.

```{=html}
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
```

```{r chunk_chapter4_task_1, message=FALSE, warning=FALSE}

```

```{=html}
    </p>
  </details>
  <br/><hr/>
```


### Non-normality and Outliers

What can we do if, after accounting for the functional relationship, response transformation and variance modelling, residual diagnostic 2 shows non-normality, in particular strong outliers? Here simulated example data with strong outliers/deviations from normality:

```{r chunk_chapter4_chunk16, echo=TRUE, eval=TRUE}
set.seed(123)

n = 100
concentration = runif(n, -1, 1)
growth = 2 * concentration + rnorm(n, sd = 0.5) +
  rbinom(n, 1, 0.05) * rnorm(n, mean = 6*concentration, sd = 6)
plot(growth ~ concentration)
```

Fitting the model, we see that the distribution is to wide:

```{r chunk_chapter4_chunk17, echo=TRUE, eval=TRUE}
fit = lm(growth ~ concentration)
par(mfrow = c(2, 2))
plot(fit)
```

What can we do to deal with such distributional problems and outliers?

* **Removing** - Bad option, hard to defend, reviewers don't like this - if at all, better show robustness with and without outlier, but result is sometimes not robust.
* **Change the distribution** - Fit a model with a different distribution, i.e. GLM or other. -> We will do this on Wednesday.
* **Robust regressions**.
* **Quantile regression** - A special type of regression that does not assume a particular residual distribution.

***Change distribution***

If we want to change the distribution, we have to go to a GLM, see Wednesday.

***Robust regression***

Robust methods generally refer to methods that are robust to violation of assumptions, e.g. outliers. More specifically, standard robust regressions typically downweight datap oints that have a too high influence on the fit. See <a href="https://cran.r-project.org/web/views/Robust.html" target="_blank" rel="noopener">https://cran.r-project.org/web/views/Robust.html</a> for a list of robust packages in R.

```{r chunk_chapter4_chunk18, echo=TRUE, eval=TRUE}
# This is the classic method.
library(MASS)

fit = rlm(growth ~ concentration) 
summary(fit)
# No p-values and not sure if we can trust the confidence intervals.
# Would need to boostrap by hand!

# This is another option that gives us p-values directly.
library(robustbase)

fit = lmrob(growth ~ concentration) 
summary(fit)
```

***Quantile regression***

Quantile regressions don't fit a line with an error spreading around it, but try to fit a quantile (e.g. the 0.5 quantile, the median) regardless of the distribution. Thus, they work even if the usual assumptions don't hold.

```{r chunk_chapter4_chunk19, echo=TRUE, eval=TRUE}
library(quantreg)

fit = rq(growth ~ concentration,.5) 
summary(fit)
summary(fit, se = "boot")
```

Alternative and very useful "quantreg" package: 
<a href="https://cran.r-project.org/web/packages/lqmm/index.html" target="_blank" rel="noopener">https://cran.r-project.org/web/packages/lqmm/index.html</a>

***Summary***

Actions on **real outliers**:

* Robust regression.
* Remove

Actions on **different distributions**:

* Transform.
* Change distribution or quantile regression.


## Random and Mixed Effects - Motivation

Random effects are a very common addition to regression models that can be used for any type of grouping (categorical) variable. Lets look at the Month in airquality:

```{r chunk_chapter4_chunk20, echo=TRUE, eval=TRUE}
airquality$fMonth = as.factor(airquality$Month)
```

Let's say further that we are only interested in calculating the mean of Ozone:

```{r chunk_chapter4_chunk21, echo=TRUE, eval=TRUE}
fit = lm(Ozone ~ 1, data = airquality)
```

Problem: If we fit residuals, we see that they are correlated in Month, so we somehow have to account for Month:

```{r chunk_chapter4_chunk22, echo=TRUE, eval=TRUE}
plot(residuals(fit) ~ airquality$fMonth[as.numeric(row.names(model.frame(fit)))])
```

A fixed effect model for fMonth would be

```{r chunk_chapter4_chunk23, echo=TRUE, eval=TRUE}
fit = lm(Ozone ~ fMonth, data = airquality)
summary(fit)
```

However, using a fixed effect costs a lot of degrees of freedom, and maybe we are not really interested in Month, we just want to correct the correlation in the residuals.

Solution: **Mixed / random effect models**. In a mixed model, we assume (differently to a fixed effect model) that the effect of Month is coming from a normal distribution. In a way, you could say that there are two types of errors:

* The random effect, which is a normal "error" per group (in this case Month).

* And the residual error, which comes on top of the random effect.

Because of this hierarchical structure, these models are also called "multi-level models" or "hierarchical models".
Nomenclature:

* No random effect = Fixed effect model.
* Only random effects + intercept = Random effect model.
* Random effects + fixed effects = Mixed model.

Because grouping naturally occurs in any type of experimental data (batches, blocks, etc.), mixed effect models are the de-facto default for most experimental data! Mind, that grouping even occurs for example, when 2 different persons gather information.


### Fitting Random Effects Models

To speak about random effects, we will use an example data set containing exam scores of 4,059 students from 65 schools in Inner London. This data set is located in the R package "mlmRev".

* Response:   "normexam" (Normalized exam score).
* Predictor 1: "standLRT" (Standardised LR test score; Reading test taken when they were 11 years old).
* Predictor 2: "sex" of the student (F/M).

If we analyze this with a simple lm, we get the following response:

```{r chunk_chapter4_chunk24, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(mlmRev)
library(effects)

mod0 = lm(normexam ~ standLRT + sex , data = Exam)
plot(allEffects(mod0))
```

***Random intercept model***

A random intercept model assumes that each school gets their own intercept. It's pretty much identical to the fixed effect model `lm(normexam ~ standLRT + sex + school)`{.R}, except that instead of giving each school a separate independent intercept, we assume that the school effects come from a common normal distribution. 

```{r chunk_chapter4_chunk25, echo=TRUE, eval=TRUE}
mod1 = lmer(normexam ~ standLRT + sex +  (1 | school), data = Exam)
summary(mod1)
```

If we look at the outputs, we see that the effects of school are not explicitly mentioned, i.e. we fit an average over the schools. This is also because we treat the random effects as error rather than as estimates. 

However, the school mean effects are estimated, and we can make them visible, e.g. via:

```{r chunk_chapter4_chunk26, echo=TRUE, eval=TRUE}
with(Exam, {
  par(mfrow = c(1, 2))
  randcoef = ranef(mod1)$school[,1]
  fixedcoef = fixef(mod1)
  plot(standLRT, normexam)
    for(i in 1:65){
      abline(a = fixedcoef[1] + randcoef[i], b = fixedcoef[2], col = i)
    }
})
```

***Random slope model***

A random slope model assumes that each school also gets their own slope for a given parameter (per default we will always estimate slope and intercept, but you could overwrite this, not recommended!). Let's do this for standLRT (you could of course do both as well). 

```{r chunk_chapter4_chunk27, echo=TRUE, eval=TRUE}
mod2 = lmer(normexam ~ standLRT + sex +  (standLRT | school), data = Exam)
summary(mod2)
```

Fitting a random slope on standLRT is pretty much identical to fit the fixed effect model  
`lm(normexam ~ standLRT*school + sex)`{.R}, except that school is a random effect, and therefore parameter estimates for the interaction sex:school are not independent. The results is similar to the random intercept model, except that we have an additional variance term.

Here a visualization of the results 

```{r chunk_chapter4_chunk28, echo=TRUE, eval=TRUE}
with(Exam, {
  randcoefI = ranef(mod2)$school[,1]
  randcoefS = ranef(mod2)$school[,2]
  fixedcoef = fixef(mod2)
  plot(standLRT, normexam)
    for(i in 1:65){
      abline(a = fixedcoef[1] + randcoefI[i] , b = fixedcoef[2] + randcoefS[i], col = i)
    }
})
```

***Syntax cheat sheet:***

* Random intercept: `(1 | group).
* ONLY random slope for a given fixed effect: `(0 + fixedEffect | group)`{.R}.
* Random slope + intercept + correlation (default): `(fixedEffect | group)`{.R}.
* Random slope + intercept without correlation: `(fixedEffect || group)`{.R}, identical to  
`(1 | group) + (0 + fixedEffect | group)`{.R}.
* Nested random effects:  `(1 | group / subgroup)`{.R}. If groups are labeled A, B, C, ... and subgroups 1, 2, 3, ..., this will create labels A1, A2 ,B1, B2, so that you effectively group in subgroups. Useful for the many experimental people that do not label subgroups uniquely, but otherwise no statistical difference to a normal random effect.
* Crossed random effects: You can add random effects independently, as in  
`(1 | group1) + (1 | group2)`{.R}. 


### Case Study 1: College Student Performance Over Time

***Background and data structure***

The GPA (college grade point average) data is a longitudinal data set, where 200 college students and their GPA have been followed 6 consecutive semesters. Look at the GPA (<a href="https://elearning.uni-regensburg.de/pluginfile.php/2365103/mod_book/chapter/72387/gpa.RData" target="_blank" rel="noopener">download</a>) data set, retrieved from <a href="https://m-clark.github.io/mixed-models-with-R/" target="_blank" rel="noopener">https://m-clark.github.io/mixed-models-with-R/</a>.

```{r chunk_chapter4_chunk29, echo=TRUE, eval=FALSE, purl=FALSE}
# Loading data in RData format will attach objects, here "gpa", in the same environment.
load("gpa.RData")
str(gpa)
```

In this data set, there are GPA measures on 6 consecutive **occasions**, with a **job** status variable (how many hours worked) for the same 6 occasions. There are two student-level explanatory variables: The **sex** (1 = male, 2 = female) and the high school **gpa**. There is also a dichotomous student-level outcome variable, which indicates whether a student has been **admitted** to the university of their choice. Since not every student applies to a university, this variable has many missing values. Each **student** and each **year** of observation have an id.

```{=html}
  <hr/>
  <strong><span style="color: #0011AA; font-size:25px;">Task</span></strong><br/>
```

Analyze if GPA improves over time (**occasion**)!

Hint: The amount and trend of GPA from one student are not independent. Do a standard linear regression and a mixed effects regression, including random intercept and slope for the grouping variable **student**. Compare the confidence intervals (Hint: `?confint`{.R}) and the coefficients (`?coef`{.R}) of the standard linear model and the mixed effects model. Look at the random effects estimates of the mixed effects model (hint: `?ranef`{.R}).

Advanced / optional:

* Look at a visualziation of the random slopes at:  
<a href="https://m-clark.github.io/mixed-models-with-R/random_slopes.html#visualization-of-effects" target="_blank" rel="noopener">https://m-clark.github.io/mixed-models-with-R/random_slopes.html#visualization-of-effects</a>.
* Execute and understand the generative simulation of random slopes at:  
<a href="https://m-clark.github.io/mixed-models-with-R/random_slopes.html#exercises-for-random-slopes" target="_blank" rel="noopener">https://m-clark.github.io/mixed-models-with-R/random_slopes.html#exercises-for-random-slopes</a>.

```{=html}
  <details>
    <summary>
      <strong><span style="color: #0011AA; font-size:25px;">Solution</span></strong>
    </summary>
    <p>
```

```{r chunk_chapter4_task_2, message=FALSE, warning=FALSE}

```

```{=html}
    </p>
  </details>
  <br/><hr/>
```


### Problems With Mixed Models

Specifying mixed models is quite simple, however, there is a large list of (partly quite complicate) issues in their practical application. Here, a (incomplete) list: 

***Interpretation of random effects***

What do the random effects mean? The classical interpretation is that they are a structured error, so they are basically group residuals and are not of further importance. However, people increasingly see random effects also as a means to fit effects that could otherwise not be fittet. For example, if we have data for common and rare species, and we are interested in the density dependence of the species, we could fit

```{r chunk_chapter4_chunk30, echo=TRUE, eval=FALSE, purl=FALSE}
mortality ~ density + (density | species)
```

In such a model, we have the mean density effect across all species, and rare species with few data will be constrained by this effect, while common species with a lot of data can overrule the normal distribution imposed by the random slope and get their own estimate. In this picture, the random effect imposes an adaptive shrinkage, similar to a LASSO or ridge shrinkage estimator, with the shrinkage strength controlled by the standard deviation of the random effect. 

***Degrees of freedom for a random effect***

The second problem is: How many parameters does a random effect model have? To know how many parameters the model hss is crucial for calculating p-values, AIC and all that. We can estimate roughly how many parameters we should have by looking at the fixed effect version of the models: 

```{r chunk_chapter4_chunk31, echo=TRUE, eval=TRUE}
mod1 = lm(normexam ~ standLRT + sex , data = Exam)
mod1$rank # 3 parameters.

mod2 = lmer(normexam ~ standLRT + sex +  (1 | school), data = Exam)
# No idea how many parameters.

mod3 = lm(normexam ~ standLRT + sex + school, data = Exam)
mod3$rank # 67 parameters.
```

What we can say is that the mixed model is more complicated than mod1, but less than mod2 (as it has the additional constraint), so the complexity must be somewhere in-between. But now much? 

In fact, the complexity is controlled by the estimated variance of the random effect. For a high variance, the model is nearly as complex as mod3, for a low variance, it is only as complex as mod1. Because of these issues, `lmer`{.R} by default does not return p-values. However, you can calculate p-values based on approximate degrees of freedom via the `lmerTest`{.R} package, which also corrects ANOVA for random effeects, but not AIC.

```{r chunk_chapter4_chunk32, echo=TRUE, eval=TRUE}
library(lmerTest)

m2 = lmer(normexam ~ standLRT + sex +  (1 | school), data = Exam, REML = F)
summary(m2)
```

***Variance partitioning / ANOVA***

Also variance partitioning is a bit tricky, as (see type I/II/III ANOVA discussion) fixed and random components of the model are in some way "correlated". The question is: Do you want to count the random effect variance as "explained", or "residual". The most common approach is the hierarchical partitioning proposed by by *Nakagawa & Schielzeth 2013, Nakagawa et al. (2017)*, which is implemented in the MuMIn package. With this, we can run 

```{r chunk_chapter4_chunk33, echo=TRUE, eval=TRUE}
library(MuMIn)

r.squaredGLMM(m2) 
```

Interpretation

* R2m: Marginal ${R}^{2}$ value associated with fixed effects.
* R2c: Conditional ${R}^{2}$ value associated with fixed effects plus the random effects.


### Case Study 2 - Honeybee Data












